{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA y Tranformaciones de los data set.\n",
    "\n",
    "Primera tranformación será pasar a formato CSV los dataset que faltan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PRODUCTOS.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Convertir cada archivo a CSV\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m archivo \u001b[38;5;129;01min\u001b[39;00m archivos_excel:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Cargar el archivo en un DataFrame\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchivo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Generar el nombre del archivo CSV\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     archivo_csv \u001b[38;5;241m=\u001b[39m archivo\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PRODUCTOS.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista de archivos Excel a convertir\n",
    "archivos_excel = [\n",
    "    \"PRODUCTOS.xlsx\",\n",
    "    \"Proveedores.xlsx\",\n",
    "    \"CanalDeVenta.xlsx\"\n",
    "]\n",
    "\n",
    "# Convertir cada archivo a CSV\n",
    "for archivo in archivos_excel:\n",
    "    # Cargar el archivo en un DataFrame\n",
    "    df = pd.read_excel(archivo)\n",
    "\n",
    "    # Generar el nombre del archivo CSV\n",
    "    archivo_csv = archivo.replace(\".xlsx\", \".csv\")\n",
    "\n",
    "    # Guardar en formato CSV\n",
    "    df.to_csv(archivo_csv, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"Archivo convertido: {archivo_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximo paso.\n",
    "\n",
    "Será conocer los dataset, ver si hay errores, nulos , duplicados, outliers, para una posterior transformación de cada dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Error</th>\n",
       "      <th>Filas</th>\n",
       "      <th>Columnas</th>\n",
       "      <th>Nulos (%)</th>\n",
       "      <th>Duplicados</th>\n",
       "      <th>Outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clientes</td>\n",
       "      <td>Error tokenizing data. C error: Expected 3 fie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11539.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Empleados</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gasto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8640.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRODUCTOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>291.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.030928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Proveedores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sucursales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TiposDeGasto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Venta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46645.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.389324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset                                              Error    Filas  \\\n",
       "0      Clientes  Error tokenizing data. C error: Expected 3 fie...      NaN   \n",
       "1        Compra                                                NaN  11539.0   \n",
       "2     Empleados                                                NaN    267.0   \n",
       "3         Gasto                                                NaN   8640.0   \n",
       "4     PRODUCTOS                                                NaN    291.0   \n",
       "5   Proveedores                                                NaN     14.0   \n",
       "6    Sucursales                                                NaN     31.0   \n",
       "7  TiposDeGasto                                                NaN      4.0   \n",
       "8         Venta                                                NaN  46645.0   \n",
       "\n",
       "   Columnas  Nulos (%)  Duplicados  Outliers  \n",
       "0       NaN        NaN         NaN       NaN  \n",
       "1       6.0   0.000000         0.0     446.0  \n",
       "2       7.0   0.000000         0.0       6.0  \n",
       "3       5.0   0.000000         0.0     174.0  \n",
       "4       4.0   1.030928         0.0       3.0  \n",
       "5       7.0   2.040816         0.0       1.0  \n",
       "6       1.0   0.000000         0.0       1.0  \n",
       "7       3.0   0.000000         0.0       1.0  \n",
       "8      10.0   0.389324         0.0    2236.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reimportar librerías después del reinicio del estado\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Lista de archivos CSV\n",
    "archivos_csv = {\n",
    "    \"Clientes\": \"Clientes.csv\",\n",
    "    \"Compra\": \"Compra.csv\",\n",
    "    \"Empleados\": \"Empleados.csv\",\n",
    "    \"Gasto\": \"Gasto.csv\",\n",
    "    \"PRODUCTOS\": \"PRODUCTOS.csv\",\n",
    "    \"Proveedores\": \"Proveedores.csv\",\n",
    "    \"Sucursales\": \"Sucursales.csv\",\n",
    "    \"TiposDeGasto\": \"TiposDeGasto.csv\",\n",
    "    \"Venta\": \"Venta.csv\"\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar los DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Cargar y analizar cada dataset\n",
    "resumen_datasets = []\n",
    "\n",
    "for nombre, ruta in archivos_csv.items():\n",
    "    try:\n",
    "        # Cargar el dataset\n",
    "        df = pd.read_csv(ruta)\n",
    "        dataframes[nombre] = df  # Guardar en el diccionario\n",
    "\n",
    "        # Obtener información básica\n",
    "        info_basica = {\n",
    "            \"Dataset\": nombre,\n",
    "            \"Filas\": df.shape[0],\n",
    "            \"Columnas\": df.shape[1],\n",
    "            \"Nulos (%)\": df.isnull().sum().sum() / df.size * 100,\n",
    "            \"Duplicados\": df.duplicated().sum(),\n",
    "            \"Outliers\": np.sum((df.select_dtypes(include=[np.number]) > df.select_dtypes(include=[np.number]).quantile(0.99)).sum())\n",
    "        }\n",
    "\n",
    "        resumen_datasets.append(info_basica)\n",
    "    \n",
    "    except Exception as e:\n",
    "        resumen_datasets.append({\"Dataset\": nombre, \"Error\": str(e)})\n",
    "\n",
    "# Convertir en DataFrame y mostrar\n",
    "df_resumen = pd.DataFrame(resumen_datasets)\n",
    "df_resumen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformaciones de datasets. \n",
    "\n",
    "### Transformaciones Aplicadas al Dataset \"Clientes.csv\"\n",
    "Ahora vamos a realziar la limpieza de datos y su tranformación:\n",
    "\n",
    "1. Tratar los valores nulos\n",
    "\n",
    "- Rellenar valores categóricos con \"el mismo nombre del registro anterior y posterior si coinciden\" y valores numéricos con la mediana.\n",
    "\n",
    "2. Corrección de tipos de datos\n",
    "\n",
    "- identificar y convertir columnas de fecha correctamente:\n",
    "    - \"Fecha_Alta\"\n",
    "    - \"Fecha_Ultima_Modificacion\"\n",
    "\n",
    "3. Normalización de textos\n",
    "limpiaro espacios extras y convertido los textos a minúsculas en todas las columnas categóricas.Tambien si hubere \";\" se pasará a \",\". \n",
    "\n",
    "4. Eliminación de los datos nulos, eliminar la fila. \n",
    "\n",
    "5. Guardar el documento en la carpeta CSV_tranformados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3407 entries, 0 to 3406\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   ID                           3407 non-null   int64  \n",
      " 1   Provincia                    3376 non-null   object \n",
      " 2   Nombre_y_Apellido            3361 non-null   object \n",
      " 3   Domicilio                    3359 non-null   object \n",
      " 4   Telefono                     3317 non-null   object \n",
      " 5   Edad                         3407 non-null   int64  \n",
      " 6   Localidad                    3375 non-null   object \n",
      " 7   X                            3345 non-null   object \n",
      " 8   Y                            3347 non-null   object \n",
      " 9   Fecha_Alta                   3407 non-null   object \n",
      " 10  Usuario_Alta                 3407 non-null   object \n",
      " 11  Fecha_Ultima_Modificacion    3407 non-null   object \n",
      " 12  Usuario_Ultima_Modificacion  3407 non-null   object \n",
      " 13  Marca_Baja                   3407 non-null   int64  \n",
      " 14  col10                        0 non-null      float64\n",
      "dtypes: float64(1), int64(3), object(11)\n",
      "memory usage: 399.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    ID     Provincia        Nombre_y_Apellido  \\\n",
       " 0   1  Buenos Aires       HEBER JONI SANTANA   \n",
       " 1   2  Buenos Aires              ANA SAPRIZA   \n",
       " 2   3  Buenos Aires  FERNANDO LUIS SARALEGUI   \n",
       " 3   4  Buenos Aires         MANUELA SARASOLA   \n",
       " 4   5  Buenos Aires       MARIO RAÚL SARASUA   \n",
       " \n",
       "                                            Domicilio  Telefono  Edad  \\\n",
       " 0  LAS HERAS Y BAT. 24 DE FEBRERO 4150  RINCON DE...   42-5161    58   \n",
       " 1  PUEYRREDON Y DUPUY RUTA3 KM 52.500 S/N  BÂº LO...   49-7578    61   \n",
       " 2                           CALDERON DE LA BARCA 498   49-3435    15   \n",
       " 3                  RUTA 36 KM 45,500 S/N  EL PELIGRO   49-2883    29   \n",
       " 4                     492 Y 186 S/N  COLONIA URQUIZA  491-4608    34   \n",
       " \n",
       "              Localidad             X             Y  Fecha_Alta Usuario_Alta  \\\n",
       " 0           LOMA VERDE  -58,81850307  -34,30997088  2015-01-01        user1   \n",
       " 1           SANTA ROSA  -58,73073751  -34,93908311  2015-01-01        user1   \n",
       " 2               TORRES  -59,12794068  -34,43082199  2015-01-01        user1   \n",
       " 3             RUTA SOL  -58,14393954  -34,92052706  2015-01-01        user1   \n",
       " 4  JOSE MELCHOR ROMERO    -58,089381   -34,9444471  2015-01-01        user1   \n",
       " \n",
       "   Fecha_Ultima_Modificacion Usuario_Ultima_Modificacion  Marca_Baja  col10  \n",
       " 0                2015-01-01                       user1           0    NaN  \n",
       " 1                2015-01-01                       user1           0    NaN  \n",
       " 2                2015-01-01                       user1           0    NaN  \n",
       " 3                2015-01-01                       user1           0    NaN  \n",
       " 4                2015-01-01                       user1           0    NaN  )"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo nuevamente con el delimitador correcto\n",
    "df = pd.read_csv(file_path, delimiter=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Mostrar información del dataset para verificar su correcta carga\n",
    "df.info(), df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3317 entries, 0 to 3404\n",
      "Data columns (total 14 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   ID                           3317 non-null   int64         \n",
      " 1   Provincia                    3317 non-null   object        \n",
      " 2   Nombre_y_Apellido            3317 non-null   object        \n",
      " 3   Domicilio                    3317 non-null   object        \n",
      " 4   Telefono                     3317 non-null   object        \n",
      " 5   Edad                         3317 non-null   int64         \n",
      " 6   Localidad                    3317 non-null   object        \n",
      " 7   X                            3317 non-null   float64       \n",
      " 8   Y                            3317 non-null   float64       \n",
      " 9   Fecha_Alta                   3317 non-null   datetime64[ns]\n",
      " 10  Usuario_Alta                 3317 non-null   object        \n",
      " 11  Fecha_Ultima_Modificacion    3317 non-null   datetime64[ns]\n",
      " 12  Usuario_Ultima_Modificacion  3317 non-null   object        \n",
      " 13  Marca_Baja                   3317 non-null   int64         \n",
      "dtypes: datetime64[ns](2), float64(2), int64(3), object(7)\n",
      "memory usage: 388.7+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerom\\AppData\\Local\\Temp\\ipykernel_18928\\309919525.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[categorical_columns] = df[categorical_columns].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Eliminar la columna \"col10\" que solo contiene valores nulos\n",
    "df.drop(columns=[\"col10\"], inplace=True)\n",
    "\n",
    "# 2. Reemplazar valores nulos en categóricas con el valor anterior o posterior si coinciden\n",
    "categorical_columns = [\"Provincia\", \"Nombre_y_Apellido\", \"Domicilio\", \"Localidad\"]\n",
    "df[categorical_columns] = df[categorical_columns].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# 3. Reemplazar valores nulos en numéricas con la mediana\n",
    "numerical_columns = [\"X\", \"Y\"]\n",
    "df[numerical_columns] = df[numerical_columns].replace(',', '.', regex=True).astype(float)\n",
    "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].median())\n",
    "\n",
    "# 4. Convertir las columnas de fecha al formato datetime\n",
    "df[\"Fecha_Alta\"] = pd.to_datetime(df[\"Fecha_Alta\"], errors='coerce')\n",
    "df[\"Fecha_Ultima_Modificacion\"] = pd.to_datetime(df[\"Fecha_Ultima_Modificacion\"], errors='coerce')\n",
    "\n",
    "# 5. Normalización de textos: convertir a minúsculas y eliminar espacios extras\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].str.strip().str.lower()\n",
    "\n",
    "# 6. Eliminar filas que aún tengan valores nulos\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Mostrar información del dataset después de la limpieza\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CSV_tranformados/Clientes_transformados.csv'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el archivo transformado con coma como delimitador\n",
    "output_path_comma = \"CSV_tranformados/Clientes_transformados.csv\"\n",
    "df.to_csv(output_path_comma, index=False, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Devolver la ruta del archivo transformado con coma\n",
    "output_path_comma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IdCompra,Fecha,IdProducto,Cantidad,Precio,IdProveedor\\n',\n",
       " '1,2015-01-30,42832,13,560.51,12\\n',\n",
       " '2,2015-01-30,42833,11,497.58,7\\n',\n",
       " '3,2015-01-30,42834,1,588.5,6\\n',\n",
       " '4,2015-01-30,42835,9,567.66,14\\n',\n",
       " '5,2015-01-30,42839,14,231.31,2\\n',\n",
       " '6,2015-01-30,42840,14,232.07,13\\n',\n",
       " '7,2015-01-30,42841,8,236.98,4\\n',\n",
       " '8,2015-01-30,42842,4,255.33,4\\n',\n",
       " '9,2015-01-30,42845,5,578.61,12\\n']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo y revisar su contenido inicial\n",
    "file_path = \"Compra.csv\"\n",
    "\n",
    "# Leer las primeras líneas para inspeccionar el formato\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()[:10]  # Leer las primeras 10 líneas para inspección\n",
    "\n",
    "lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11539 entries, 0 to 11538\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   IdCompra     11539 non-null  int64  \n",
      " 1   Fecha        11539 non-null  object \n",
      " 2   IdProducto   11539 non-null  int64  \n",
      " 3   Cantidad     11539 non-null  int64  \n",
      " 4   Precio       11539 non-null  float64\n",
      " 5   IdProveedor  11539 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 541.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    IdCompra       Fecha  IdProducto  Cantidad  Precio  IdProveedor\n",
       " 0         1  2015-01-30       42832        13  560.51           12\n",
       " 1         2  2015-01-30       42833        11  497.58            7\n",
       " 2         3  2015-01-30       42834         1  588.50            6\n",
       " 3         4  2015-01-30       42835         9  567.66           14\n",
       " 4         5  2015-01-30       42839        14  231.31            2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo en un DataFrame\n",
    "df = pd.read_csv(file_path, delimiter=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Mostrar información del dataset antes de la limpieza\n",
    "df.info(), df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11539 entries, 0 to 11538\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   IdCompra     11539 non-null  int64         \n",
      " 1   Fecha        11539 non-null  datetime64[ns]\n",
      " 2   IdProducto   11539 non-null  int64         \n",
      " 3   Cantidad     11539 non-null  int64         \n",
      " 4   Precio       11539 non-null  float64       \n",
      " 5   IdProveedor  11539 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(4)\n",
      "memory usage: 541.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna \"Fecha\" a formato datetime\n",
    "df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"], errors='coerce')\n",
    "\n",
    "# Mostrar información después de la transformación\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CSV_tranformados/Compra_transformada.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el archivo transformado con coma como delimitador\n",
    "output_path = \"CSV_tranformados/Compra_transformada.csv\"\n",
    "df.to_csv(output_path, index=False, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Devolver la ruta del archivo transformado\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empleados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffID_empleado,Apellido,Nombre,Sucursal,Sector,Cargo,Salario\\n',\n",
       " '1968,Burgos,Jeronimo,Caseros,Administración,Administrativo,32000.00\\n',\n",
       " '1674,Villegas,Estefania,Caseros,Administración,Vendedor,32000.00\\n',\n",
       " '1516,Fernandez,Guillermo,Caseros,Administración,Vendedor,45000.00\\n',\n",
       " '1330,Ramirez,Eliana,Caseros,Administración,Vendedor,32000.00\\n',\n",
       " '1657,Carmona,Jose,Caseros,Administración,Vendedor,32000.00\\n',\n",
       " '1573,De santis,Marcela,Caseros,Administración,Aux. Administrativo,15000.00\\n',\n",
       " '1658,Franco,Daniela,Caseros,Administración,Vendedor,32000.00\\n',\n",
       " '1078,Cortes,Rafael,Caseros,Diseño,Administrativo,42000.00\\n',\n",
       " '1695,Berrio,Camilo,Cabildo,Diseño,Vendedor,32000.00\\n']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo y revisar su contenido inicial\n",
    "file_path = \"Empleados.csv\"\n",
    "\n",
    "# Leer las primeras líneas para inspeccionar el formato\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()[:10]  # Leer las primeras 10 líneas para inspección\n",
    "\n",
    "lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 267 entries, 0 to 266\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ID_empleado  267 non-null    int64  \n",
      " 1   Apellido     267 non-null    object \n",
      " 2   Nombre       267 non-null    object \n",
      " 3   Sucursal     267 non-null    object \n",
      " 4   Sector       267 non-null    object \n",
      " 5   Cargo        267 non-null    object \n",
      " 6   Salario      267 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 14.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    ID_empleado   Apellido     Nombre Sucursal          Sector           Cargo  \\\n",
       " 0         1968     Burgos   Jeronimo  Caseros  Administración  Administrativo   \n",
       " 1         1674   Villegas  Estefania  Caseros  Administración        Vendedor   \n",
       " 2         1516  Fernandez  Guillermo  Caseros  Administración        Vendedor   \n",
       " 3         1330    Ramirez     Eliana  Caseros  Administración        Vendedor   \n",
       " 4         1657    Carmona       Jose  Caseros  Administración        Vendedor   \n",
       " \n",
       "    Salario  \n",
       " 0  32000.0  \n",
       " 1  32000.0  \n",
       " 2  45000.0  \n",
       " 3  32000.0  \n",
       " 4  32000.0  )"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo en un DataFrame\n",
    "df = pd.read_csv(file_path, delimiter=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Mostrar información del dataset antes de la limpieza\n",
    "df.info(), df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_empleado</th>\n",
       "      <th>Apellido</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Sucursal</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Cargo</th>\n",
       "      <th>Salario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1968</td>\n",
       "      <td>burgos</td>\n",
       "      <td>jeronimo</td>\n",
       "      <td>caseros</td>\n",
       "      <td>administración</td>\n",
       "      <td>administrativo</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>villegas</td>\n",
       "      <td>estefania</td>\n",
       "      <td>caseros</td>\n",
       "      <td>administración</td>\n",
       "      <td>vendedor</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1516</td>\n",
       "      <td>fernandez</td>\n",
       "      <td>guillermo</td>\n",
       "      <td>caseros</td>\n",
       "      <td>administración</td>\n",
       "      <td>vendedor</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330</td>\n",
       "      <td>ramirez</td>\n",
       "      <td>eliana</td>\n",
       "      <td>caseros</td>\n",
       "      <td>administración</td>\n",
       "      <td>vendedor</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1657</td>\n",
       "      <td>carmona</td>\n",
       "      <td>jose</td>\n",
       "      <td>caseros</td>\n",
       "      <td>administración</td>\n",
       "      <td>vendedor</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_empleado   Apellido     Nombre Sucursal          Sector           Cargo  \\\n",
       "0         1968     burgos   jeronimo  caseros  administración  administrativo   \n",
       "1         1674   villegas  estefania  caseros  administración        vendedor   \n",
       "2         1516  fernandez  guillermo  caseros  administración        vendedor   \n",
       "3         1330    ramirez     eliana  caseros  administración        vendedor   \n",
       "4         1657    carmona       jose  caseros  administración        vendedor   \n",
       "\n",
       "   Salario  \n",
       "0  32000.0  \n",
       "1  32000.0  \n",
       "2  45000.0  \n",
       "3  32000.0  \n",
       "4  32000.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columnas categóricas a normalizar\n",
    "categorical_columns = [\"Apellido\", \"Nombre\", \"Sucursal\", \"Sector\", \"Cargo\"]\n",
    "\n",
    "# Normalización de textos: convertir a minúsculas y eliminar espacios extras\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].str.strip().str.lower().str.replace(\";\", \",\")\n",
    "\n",
    "# Mostrar información después de la transformación\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CSV_tranformados/Empleados_transformados.csv'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el archivo transformado con coma como delimitador\n",
    "output_path = \"CSV_tranformados/Empleados_transformados.csv\"\n",
    "df.to_csv(output_path, index=False, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Devolver la ruta del archivo transformado\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gasto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IdGasto,IdSucursal,IdTipoGasto,Fecha,Monto\\n',\n",
       " '1,18,1,2015-01-01,1164.9\\n',\n",
       " '2,18,2,2015-01-01,317.02\\n',\n",
       " '3,18,3,2015-01-01,118.89\\n',\n",
       " '4,18,4,2015-01-01,1174.23\\n',\n",
       " '5,1,1,2015-01-01,1104.51\\n',\n",
       " '6,1,2,2015-01-01,359.96\\n',\n",
       " '7,1,3,2015-01-01,108.59\\n',\n",
       " '8,1,4,2015-01-01,1029.69\\n',\n",
       " '9,2,1,2015-01-01,1090.87\\n']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo y revisar su contenido inicial\n",
    "file_path = \"Gasto.csv\"\n",
    "\n",
    "# Leer las primeras líneas para inspeccionar el formato\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()[:10]  # Leer las primeras 10 líneas para inspección\n",
    "\n",
    "lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8640 entries, 0 to 8639\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   IdGasto      8640 non-null   int64  \n",
      " 1   IdSucursal   8640 non-null   int64  \n",
      " 2   IdTipoGasto  8640 non-null   int64  \n",
      " 3   Fecha        8640 non-null   object \n",
      " 4   Monto        8640 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 337.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    IdGasto  IdSucursal  IdTipoGasto       Fecha    Monto\n",
       " 0        1          18            1  2015-01-01  1164.90\n",
       " 1        2          18            2  2015-01-01   317.02\n",
       " 2        3          18            3  2015-01-01   118.89\n",
       " 3        4          18            4  2015-01-01  1174.23\n",
       " 4        5           1            1  2015-01-01  1104.51)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el archivo en un DataFrame\n",
    "df = pd.read_csv(file_path, delimiter=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Mostrar información del dataset antes de la limpieza\n",
    "df.info(), df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8640 entries, 0 to 8639\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   IdGasto      8640 non-null   int64         \n",
      " 1   IdSucursal   8640 non-null   int64         \n",
      " 2   IdTipoGasto  8640 non-null   int64         \n",
      " 3   Fecha        8640 non-null   datetime64[ns]\n",
      " 4   Monto        8640 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3)\n",
      "memory usage: 337.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna \"Fecha\" a formato datetime\n",
    "df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"], errors='coerce')\n",
    "\n",
    "# Mostrar información después de la transformación\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CSV_tranformados/Gasto_transformado.csv'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el archivo transformado con coma como delimitador\n",
    "output_path = \"CSV_tranformados/Gasto_transformado.csv\"\n",
    "df.to_csv(output_path, index=False, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Devolver la ruta del archivo transformado\n",
    "output_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
